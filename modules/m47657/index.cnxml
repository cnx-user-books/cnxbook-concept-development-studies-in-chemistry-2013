<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Entropy and the Second Law of Thermodynamics</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m47657</md:content-id>
  <md:title>Entropy and the Second Law of Thermodynamics</md:title>
  <md:abstract/>
  <md:uuid>62b02a39-1494-4fd5-baf8-13d1d0701319</md:uuid>
</metadata>

<content>
    <section id="import-auto-id2886474">
      <title>Introduction</title><para id="import-auto-id4268445">We have spent much of the previous concept studies finding that chemical and physical processes come to equilibrium.  We have observed this in phase equilibrium of pure substances, solution equilibrium, solubility equilibrium, chemical reactions in the gas phase, and acid-base equilibrium.  In each case, we have been able to understand equilibrium as a dynamic process.  At equilibrium, there are competing processes, forward and reverse, which come to equilibrium when the rates of the competing processes are equal.  For example, when liquid and vapor are at equilibrium at the vapor pressure of the liquid, the rate of evaporation of the liquid is equal to the rate of condensation of the vapor.</para>
      <para id="import-auto-id8697853">However, our dynamic equilibrium model does not tell us the conditions at equilibrium.  For each liquid, we know that there is one pressure for each temperature at which the liquid can be in equilibrium with its vapor.  But we cannot predict or calculate what that pressure is for each temperature for each liquid.  We can only make qualitative predictions.  Thermodynamics will give us the means to make these predictions and will give us a new physical insight into the nature of equilibrium.</para>
      <para id="import-auto-id8299253">We will begin by developing a means to predict what processes will happen “spontaneously.”  This is a term chemists use to refer to processes that are not at equilibrium.  It is easiest to explain with an example.  We know that, if the pressure of water vapor is 1 atm at 25 ºC, the water vapor will spontaneously condense.  On the other hand, we have also seen that, if the pressure of water vapor is below 23 torr at 25 ºC, the liquid water will spontaneously evaporate.  These are both examples of spontaneous processes.  Note that these are opposite processes.  This means that the spontaneity of a process depends on the conditions, in this case, the pressure and the temperature.  Any process not at equilibrium is a process occurring spontaneously.  One way to understand equilibrium, then, is to understand spontaneity.  We will see that the Second Law of Thermodynamics provides us the ability to predict spontaneous processes.</para>
    </section>
    <section id="import-auto-id4721589">
      <title><emphasis effect="underline">Foundation</emphasis>       </title><para id="import-auto-id5566626">We have come a long way to reach this point, so we have a substantial foundation to build on.  We know all the elements of the Atomic Molecular Theory, including the models for molecular structure and bonding.  We have developed the postulates of the Kinetic Molecular Theory.  We have observed and defined phase transitions and phase equilibrium.  We have also observed equilibrium in a variety of reaction systems, including acids and bases.  We will assume an understanding of the energetics of chemical reactions, including the idea of a “state function” and the concept of Hess’ Law.</para>
      </section><section id="fs-id1171002506035"><title>Observation 1:  Spontaneous Mixing</title>
      <para id="import-auto-id6309244">We begin by examining common characteristics of spontaneous processes, and for simplicity, we focus on processes not involving phase transitions or chemical reactions.  A very clear example of such a process is mixing.  Imagine adding a drop of blue ink into a glass of water.  At first, the blue dye in the ink is highly concentrated.  Therefore, the molecules of the dye are closely congregated.  Slowly but steadily, the dye begins to diffuse throughout the entire glass of water, so that eventually the water appears as a uniform blue color.  This occurs more readily with agitation or stirring but occurs spontaneously even without such effort.  Careful measurements show that this process occurs without a change in temperature, so there is no energy input or released during the mixing.  </para>
      <para id="import-auto-id8320700">We conclude that, although there is no energetic advantage to the dye molecules dispersing themselves, they do so spontaneously.  Furthermore, this process is "irreversible" in the sense that, without considerable effort on our part, the dye molecules will never return to form a single localized drop.  We now seek an understanding of how and why this mixing occurs.</para>
      <para id="import-auto-id8772706">Consider the following rather abstract model for the dye molecules in the water.  For the glass, we take a row of 10 small boxes, each one of which represents a possible location for a molecule, either of water or of dye.  For the molecules, we take marbles, colorless for water and blue for ink.  Each box will accommodate only a single marble, since two molecules cannot be in the same place as the same time.  Since we see a drop of dye when the molecules are congregated, we model a "drop" as three blue marbles in consecutive boxes.  Notice that there are only eight ways to have a "drop" of dye, assuming that the three dye "molecules" are indistinguishable from one another.  Two possibilities are shown in Figures 1a and 1b.  It is not difficult to find the other six.</para>
      <para id="import-auto-id5399330">By contrast, there are many more ways to arrange the dye molecules so that they do not form a drop, i.e., so that the three molecules are not together.  Two possibilities are shown in Figures 1c and 1d.  The total number of such possibilities is 112.  (The total number of all possible arrangements can be calculated as follows: there are 10 possible locations for the first blue marble, 9 for the second, and 8 for the third.  This gives 720 possible arrangements, but many of these are identical, since the marbles are indistinguishable.  The number of duplicates for each arrangement is 6, calculated from three choices for the first marble, two for the second, and one for the third.  The total number of non-identical arrangements of the molecules is 720/6 = 120.)  We conclude that, if we randomly place the 3 marbles in the tray of 10 boxes, the chances are only 8 out of 120 (or 1 out of 15) of observing a drop of ink.  </para>
      <para id="eip-691"><figure id="eip-id1168993730483"><media id="eip-id1168985099077" alt="">
 <image mime-type="image/png" src="../../media/CDS1-62b6.png"/>
</media></figure></para><para id="import-auto-id7634259">Now, in a real experiment, there are many, many times more ink molecules and many, many times more possible positions for each molecule.  To see how this comes into play, consider a row of 500 boxes and 5 blue marbles.  (The "mole fraction" of ink is thus 0.01.)  The total number of distinct configurations of the blue marbles in these boxes is approximately 2×10<sup>11</sup>.  The number of these configurations that have all five ink marbles together in a drop is 496.  If the arrangements are sampled randomly, the chances of observing a drop of ink with all five molecules together are thus approximately one in 500 million.  The possibilities are remote even for observing a partial "droplet" consisting of fewer than all five dye molecules.  The chance for four of the molecules to be found together is about one in 800,000.  Even if we define a droplet to be only three molecules together, the chances of observing one are less than one in 1600.  </para><para id="import-auto-id5047235">We could, with some difficulty, calculate the probability for observing a drop of ink when there are 10<sup>23</sup> molecules.  However, we can reasonably extrapolate from our small calculations that the probability is essentially zero for the ink molecules, randomly distributed into the water molecules, to be found together.  The reason why we observe ink to disperse in water is that the probability is infinitesimally small for randomly distributed dye molecules to be congregated in a drop.</para><para id="import-auto-id6486712">Interestingly, however, when we set up the real ink and water experiment, we did not randomly distribute the ink molecules.  Rather, we began initially with a drop of ink in which the dye molecules were already congregated.  We know that, according to the Kinetic Molecular Theory, the molecules are in constant random motion.  Therefore, they must be constantly rearranging themselves.  Since these random motions do not energetically favor any one arrangement over any other one arrangement, we can assume that all possible arrangements are equally probable.  Since most of the arrangements do not correspond to a drop of ink, then <emphasis effect="underline">most of the time</emphasis> we will not observe a drop.  In the case above with five blue marbles in 500 boxes, we expect to see a drop only once in every 500 million times we look at the "glass."  In a real glass of water with a real drop of ink, the chances are very much smaller than this. </para><para id="import-auto-id4554905">We draw two very important conclusions from our model.  First, the random motions of molecules make every possible arrangement of these molecules equally probable.  Second, mixing occurs spontaneously simply because there are vastly many more arrangements which are mixed than which are not.  The first conclusion tells us "how" mixing occurs, and the second tells us "why."  On the basis of these observations, we deduce the following preliminary generalization: a spontaneous process occurs because it produces the most probable final state.</para>
      </section><section id="fs-id1170986707907"><title>Probability and Entropy</title>
      <para id="import-auto-id8772777">There is a subtlety in our conclusion to be considered in more detail.  We have concluded that all possible arrangements of molecules are equally probable.  We have further concluded that mixing occurs because the final mixed state is overwhelmingly probable.  Placed together, these statements appear to be openly contradictory.  To see why they are not, we must analyze the statements carefully.  By an "arrangement" of the molecules, we mean a specification of the location of each and every molecule.  We have assumed that, due to random molecular motion, each such arrangement is equally probable.  In what sense, then, is the final state "overwhelmingly probable"?</para>
      <para id="import-auto-id5124526">Recall the system illustrated in Figure 1, where we placed three identical blue marbles into ten spaces.  We calculated before that there are 120 unique ways to do this.  If we ask for the probability of the arrangement in Figure 1a, the answer is thus 1/120.  This is also the probability for each of the other possible arrangements, according to our model.  However, if we now ask instead for the probability of observing a "mixed" state (with no drop), the answer is 112/120, whereas the probability of observing an "unmixed" state (with a drop) is only 8/120.  Clearly, the probabilities are not the same when considering the less specific characteristics "mixed" and "unmixed."</para>
      <para id="import-auto-id6322570">In Chemistry we are virtually never concerned with "microscopic" details, such as the locations of specific individual molecules.  Rather, we are interested in more general characteristics, such as whether a system is mixed or not, or what the temperature or pressure is.  These properties of interest to us are "macroscopic."  As such, we refer to a specific arrangement of the molecules as a "microstate," and each general state (mixed or unmixed, for example) as a "macrostate."  All microstates have the same probability of occurring, according to our model.  As such, the macrostates have widely differing probabilities.</para>
      <para id="import-auto-id8347799">We come to an important result: the probability of observing a particular macrostate (e.g., a mixed state) is proportional to the number of microstates with that macroscopic property.  For example, from Figure 1, there are 112 arrangements (microstates) with the "mixed" macroscopic property.  As we have discussed, the probability of observing a mixed state is 112/120, which is obviously proportional to 112.  Thus, one way to measure the relative probability of a particular macrostate is by the number of microstates W corresponding to that macrostate.  W stands for "ways", i.e. there are 112 "ways" to get a mixed state in Figure 1. </para>
      <para id="import-auto-id8530182">Now we recall our conclusion that a spontaneous process always produces the outcome with greatest probability.  Since W measures this probability for any substance or system of interest, we could predict using W whether the process leading from a given initial state to a given final state was spontaneous by simply comparing probabilities for the initial and final states.  For reasons described below, we instead define a function of W,  </para>
      <para id="import-auto-id8590161">S(W)  = k ln W  , <space/><space/></para><para id="import-auto-id7360297">called the "entropy," which can be used to make such predictions about spontaneity.  (The "k" is a proportionality constant that gives S appropriate units for our calculations.)  Notice that the more microstates there are, the greater the entropy is.  Therefore, a macrostate with a high probability (e.g. a mixed state) has a large entropy.  We now modify our previous deduction to say that a spontaneous process produces the final state of greatest entropy.  (Following modifications added below, this statement forms the Second Law of Thermodynamics.)</para>
      <para id="import-auto-id7018127">It would seem that we could use W for our calculations and that the definition of the new function S is unnecessary.  However, the following reasoning shows that W is not a convenient function for calculations.  We consider two identical glasses of water at the same temperature.  We expect that the value of any physical property for the water in two glasses is twice the value of that property for a single glass.  For example, if the enthalpy of the water in each glass is H<sub>1</sub>, then it follows that the total enthalpy of the water in the two glasses together is H<sub>total</sub> = 2H<sub>1</sub>.  Thus, the enthalpy of a system is proportional to the quantity of material in the system: if we double the amount of water, we double the enthalpy.  In direct contrast, we consider the calculation involving W for these two glasses of water.  The number of microstates of the macroscopic state of one glass of water is W<sub>1</sub>, and likewise the number of microstates in the second glass of water is W<sub>1</sub>.  However, if we combine the two glasses of water, the number of microstates of the total system is found from the product W<sub>total</sub> =  W<sub>1</sub> × W<sub>1</sub>, which does not equal 2W<sub>1</sub>.  In other words, W is not proportional to the quantity of material in the system.  This is inconvenient, since the value of W thus depends on whether the two systems are combined or not.  (If it is not clear that we should multiply the W values, consider the simple example of rolling dice. The number of states for a single die is 6, but for two dice the number is 6 × 6 = 36, not 6 + 6 = 12.)</para><para id="import-auto-id7380245">We therefore need a new function S(W), so that, when we combine the two glasses of water, S<sub>total</sub> = S<sub>1</sub> + S<sub>1</sub>.  Since S<sub>total</sub> = S(W <sub>total</sub>), S<sub>1</sub>=S(W<sub>1</sub>), and W<sub>total </sub>= W<sub>1</sub> × W<sub>1</sub>, then our new function S must satisfy the equation</para><para id="import-auto-id5044118">S(W<sub>1</sub> × W<sub>1</sub>)  =  S(W<sub>1</sub>)  +  S(W<sub>1</sub>)</para><para id="import-auto-id2205790">The only function S which will satisfy this equation is the logarithm function, which has the property that  ln(x × y) = ln(x) + ln(y).  We conclude that an appropriate state function that measures the number of microstates in a particular macrostate is</para><para id="import-auto-id8600632">S = k ln W <space/><space/></para></section><section id="fs-id1170994140960"><title>Observation 2: Absolute Entropies</title>
      <para id="import-auto-id3015248">It is possible, though exceedingly difficult, to calculate the entropy of any system under any conditions of interest from the equation S = k ln W.  It is also possible, using more advanced theoretical thermodynamics, to experimentally determine S by measuring heat capacities and enthalpies of phase transitions.  Values of S determined experimentally, often referred to as "absolute" entropies, have been tabulated for many materials at many temperatures.  A few examples are given in Table 1 measured at pressure of 1 atm. (The superscript º on S indicates standard pressure. It turns out that, for gases, the entropy depends significantly on the pressure.)  Our goal is to analyze these data in the context of Equation (1). </para>
      <para id="import-auto-id8031026">There are several interesting trends observed in Table 1.  First, if we compare the entropy of the gaseous form of a substance to either its liquid or solid form at the same temperature, we find that the gas always has a substantially greater entropy.  This makes sense from Equation (1): the molecules in the gas phase occupy a very much larger volume.  There are many more possible locations for each gas molecule and thus many more arrangements of the molecules in the gas.  This means that W should be larger for a gas, and therefore the entropy of a gas is greater than that of the corresponding liquid or solid. </para>
      <para id="import-auto-id7633527">Second, we can see in the table that the entropy of a liquid is always greater than that of the corresponding solid.  This is understandable from our kinetic molecular view of liquids and solids.  Although the molecules in the liquid occupy a comparable volume to that of the molecules in the solid, each molecule in the liquid is free to move throughout this entire volume.  The molecules in the solid are relatively fixed in location.  Therefore, the number of arrangements of molecules in the liquid is significantly greater than that in the solid, so the liquid has greater entropy by Equation (1).</para>
      <table id="import-auto-id4749563" summary="Absolute Entropies of Specific Substances"><title>Absolute Entropies of Specific Substances</title>
<tgroup cols="3"><colspec colnum="1" colname="c1"/>
          <colspec colnum="2" colname="c2"/>
          <colspec colnum="3" colname="c3"/>
          <thead>
            <row>
              <entry/>
              <entry>T  (ºC )</entry>
              <entry>Sº(J/mol·ºC )</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>H<sub>2</sub>O (g)</entry>
              <entry>25</entry>
              <entry>188.8</entry>
            </row>
            <row>
              <entry>H<sub>2</sub>O (l)</entry>
              <entry>25</entry>
              <entry>69.9</entry>
            </row>
            <row>
              <entry>H<sub>2</sub>O (l)</entry>
              <entry>0</entry>
              <entry>63.3</entry>
            </row>
            <row>
              <entry>H<sub>2</sub>O (s)</entry>
              <entry>0</entry>
              <entry>41.3</entry>
            </row>
            <row>
              <entry>NH<sub>3</sub> (g)</entry>
              <entry>25</entry>
              <entry>192.4</entry>
            </row>
            <row>
              <entry>HN<sub>3</sub> (l)</entry>
              <entry>25</entry>
              <entry>140.6</entry>
            </row>
            <row>
              <entry>HN<sub>3</sub> (g)</entry>
              <entry>25</entry>
              <entry>239.0</entry>
            </row>
            <row>
              <entry>O<sub>2</sub> (g)</entry>
              <entry>25</entry>
              <entry>205.1</entry>
            </row>
            <row>
              <entry>O<sub>2</sub> (g)</entry>
              <entry>50</entry>
              <entry>207.4</entry>
            </row>
            <row>
              <entry>O<sub>2</sub> (g)</entry>
              <entry>100</entry>
              <entry>211.7</entry>
            </row>
            <row>
              <entry>CO (g)</entry>
              <entry>25</entry>
              <entry>197.7</entry>
            </row>
            <row>
              <entry>CO (g)</entry>
              <entry>50</entry>
              <entry>200.0</entry>
            </row>
            <row>
              <entry>CO<sub>2</sub> (g)</entry>
              <entry>24</entry>
              <entry>213.7</entry>
            </row>
            <row>
              <entry>CO<sub>2</sub> (g)</entry>
              <entry>50</entry>
              <entry>216.9</entry>
            </row>
            <row>
              <entry>Br<sub>2</sub> (l)</entry>
              <entry>25</entry>
              <entry>152.2</entry>
            </row>
            <row>
              <entry>Br<sub>2</sub> (g)</entry>
              <entry>25</entry>
              <entry>245.5</entry>
            </row>
            <row>
              <entry>I<sub>2</sub> (s)</entry>
              <entry>25</entry>
              <entry>116.1</entry>
            </row>
            <row>
              <entry>I<sub>2</sub> (g)</entry>
              <entry>25</entry>
              <entry>260.7</entry>
            </row>
            <row>
              <entry>CaF<sub>2</sub> (s)</entry>
              <entry>25</entry>
              <entry>68.9</entry>
            </row>
            <row>
              <entry>CaCl<sub>2</sub> (s)</entry>
              <entry>25</entry>
              <entry>104.6</entry>
            </row>
            <row>
              <entry>CaBr<sub>2</sub> (s)</entry>
              <entry>25</entry>
              <entry>130</entry>
            </row>
            <row>
              <entry>C<sub>8</sub>H<sub>18</sub> (l)</entry>
              <entry>25</entry>
              <entry>361.1</entry>
            </row>
          </tbody>
        

</tgroup>
</table><para id="import-auto-id7722432">Third, the data show that the entropy of a substance increases with increasing temperature.  We have previously found that the temperature of a substance is a measure of the average kinetic energy of the molecules in the substance.  In a solid or liquid, then, increasing the temperature increases the total kinetic energy available to the molecules.  The greater the energy, the more ways there are to distribute this energy amongst the molecules.  Although we have previously only referred to the range of positions for a molecule as affecting W, the range of energies available for each molecule similarly affects W.  As a result, as we increase the total energy of a substance, we increase W and thus the entropy.</para>
      <para id="import-auto-id7571837">Fourth, the entropy of a substance whose molecules contain many atoms is greater than that of a substance composed of smaller molecules. This is somewhat new to us.  We have discussed the structures of molecules in terms of specific geometries.  However, these structures are not rigid.  The atoms within a molecule vibrate, or wiggle, back and forth about the geometry the molecule.  The more atoms there are in a molecule, the more ways there are for those atoms to wiggle with respect to each other.  With this greater internal flexibility, W is larger when there are more atoms, so the entropy is greater.</para>
      <para id="import-auto-id8428894">Fifth, the entropy of a substance with a high molecular weight is greater than that of substance with a low molecular weight, even if the number of atoms is the same or nearly the same.  This result is a harder to understand because it does not relate to the positions that the atoms can occupy. It is clear that the number of arrangements of the molecules is <emphasis effect="underline">not</emphasis> affected by the masses of the molecules.  However, one way to describe the state of a molecule would be to specify its position and its momentum.  (In quantum mechanics, we know that it is not possible to specify both the position and the momentum, but this non-quantum explanation is easier to visualize than the quantum explanation.)  The range of momenta available for a heavier molecule is greater than for a lighter one, even at the same temperature.  To see why, recall that the momentum of a molecule is <emphasis effect="italics">p = mv</emphasis> and the kinetic energy is <emphasis effect="italics">KE = (1/2)mv<sup>2</sup> = (1/2m)p<sup>2</sup></emphasis>.  Therefore, the maximum momentum available at a fixed temperature and a fixed total kinetic energy KE is <emphasis effect="italics">p =  √2mKE</emphasis>.  When <emphasis effect="italics">m</emphasis> is larger for larger mass molecules, the range of momenta is greater for heavier particles.  With more possible states for each molecule, W and the entropy are both larger.</para></section><section id="fs-id1171019831394"><title>Observation 3: Condensation and Freezing</title>
      <para id="import-auto-id8747724">We have concluded from our observations of spontaneous mixing that a spontaneous process always produces the final state of greatest probability and greatest entropy.  A few simple observations reveal that this is not entirely correct and that our conclusion needs some careful refinement.  For example, we have observed that the entropy of liquid water is greater than that of solid water.  This makes sense in the context of Equation (1), since the kinetic theory indicates that liquid water has a greater value of W.  Nevertheless, we observe that liquid water spontaneously freezes at temperatures below 0 ºC.  This process clearly displays a decrease in entropy and therefore evidently a shift from a more probable state to a less probable state.  This appears to directly contradict our conclusion.  </para><para id="import-auto-id6528563">Similarly, we expect to find condensation of water droplets from steam when steam is cooled.  On days of high humidity, water spontaneously liquefies from the air on cold surfaces such as the outside of a glass of ice water or the window of an air conditioned building.  In these cases, the transition from gas to liquid is clearly from a higher entropy phase to a lower entropy phase, which does not seem to follow our reasoning thus far.  In fact, our reasoning would imply that ice should always melt and water should always evaporate, no matter what the conditions are.  We have either left something out of our reasoning, or we have made a serious mistake.  Before abandoning our reasoning, let’s recall that our previous conclusions concerning entropy and probability increases were quite compelling.  We should be reluctant to abandon them.  What did we overlook?</para>
      <para id="import-auto-id7595479">One thing we have failed to take into consideration is that these phase transitions involve changes of energy and thus heat flow.  Condensation of gas to liquid and freezing of liquid to solid both involve evolution of heat.  This heat flow is of consequence because our observations also revealed that the entropy of a substance can be significantly increased by elevating its temperature. </para>
      <para id="import-auto-id8734895">One way to preserve our conclusions about spontaneity and entropy is to place a condition on their validity: a spontaneous process produces the final state of greatest probability and entropy <emphasis effect="underline">provided that</emphasis> the process does not involve the evolution of heat.  This is an unsatisfying result, however, since most physical and chemical processes involve heat transfer.  As an alternative, we can force the process not to evolve heat by <emphasis effect="underline">isolating</emphasis> the system undergoing the process: no heat can be released if there is no sink to receive the heat, and no heat can be absorbed if there is no source of heat.  Therefore, we conclude from our observations that, for a spontaneous process <emphasis effect="underline">in an isolated system</emphasis> the entropy always increases and leads us to the final state of greatest probability and entropy.  This is one statement of the Second Law of Thermodynamics:</para>
      <para id="import-auto-id3762200">∆S &gt; 0 <space/><space/><emphasis effect="italics">spontaneous process in an isolated system</emphasis></para><para id="import-auto-id3033069">It is interesting to consider one particular “isolated system,” which is the entire universe.  Since no energy or matter can transfer in or out of the universe, the universe qualifies as “isolated.”  So, another statement of the Second Law of Thermodynamics is:</para>
      <para id="import-auto-id8270805">∆S<sub>universe</sub> &gt; 0 <space/><space/><emphasis effect="italics">for any spontaneous process</emphasis></para><para id="import-auto-id8610141">Though interesting and quite general, this statement is not yet all that useful because calculating <emphasis effect="italics">S</emphasis> for the entire universe seems very difficult.  In the next Concept Development Study, we will develop a means to do that calculation fairly easily.</para>
      </section><section id="fs-id1170997850664"><title>Observation 4: Heat Transfer and Entropy Changes</title>
      <para id="import-auto-id8869493">We will begin with a simple and common observation about heat flow.  Let’s take two pieces of metal of the same mass.  It doesn’t matter what type of metal or what mass, so let’s say 100.0 g of copper.  Let’s heat one of the samples (call it sample A) to 100 ºC and cool the other (call it sample B) to 0 ºC.  Then let’s place them in contact with each other but insulated from everything surrounded them. We know from everyday experience what is going to happen, but of course, when we run the experiment, the cold metal B warms up, the hot metal A cools off, and both pieces of metal stop changing temperature only when they come to the same temperature, in this case, 50 ºC.  We say that they have reached “thermal equilibrium.”</para><para id="import-auto-id8847900">The approach to thermal equilibrium is clearly a spontaneous process: it happens automatically, and indeed there is nothing we can do to stop it other than to isolate the two pieces of metal from each other.  Since this is a spontaneous process and since we isolated the two pieces of metal from their surroundings, then the work of the previous study tells us that, in total for system consisting of the two pieces of metal, ∆S &gt; 0.  </para>
      <para id="import-auto-id8827958">All that has happened is the transfer of heat from one piece of metal to the other.  No chemical reactions or phase changes have occurred and there has been no rearrangement of the atoms in the metal samples.  Why did this heat transfer increase the entropy?  We know from our previous study that raising the temperature of a sample by adding heat increases the entropy of the sample.  Let’s say that the amount of heat transferred into sample B was <emphasis effect="italics">q</emphasis>.  The energy of sample B goes up by <emphasis effect="italics">q</emphasis> during the heat transfer.  And therefore the entropy of B must go up.</para>
      <para id="import-auto-id7243109">However, by conservation of energy, this same amount of heat <emphasis effect="italics">q</emphasis> must also transfer <emphasis effect="underline">out</emphasis> of sample A.  The energy of sample A goes down by <emphasis effect="italics">q</emphasis> during the heat transfer.  And therefore the entropy of A must go down.  Since the heat transfer is the same and the types and masses of the metal samples are the same, it would seem that the entropy increase of B should be exactly equal to the entropy decrease of A, in which case the total entropy change should be zero.  But we know that this is not true, because the transfer of heat is a spontaneous process in an isolated system, so ∆S &gt; 0.  </para>
      <para id="import-auto-id8889078">This can only mean that the entropy increase of the cold sample B must be larger than the entropy decrease of the hot sample A as they approach thermal equilibrium.  This tells us that the quantity of heat alone is not enough to predict the entropy change associated with heat transfer.  We must also know the temperature to predict the entropy change.</para>
      <para id="import-auto-id4278350">Our observations also tell us that the entropy change is greater for the lower temperature sample.  Entropy change and temperature are therefore inversely related to each other.  Adding heat to a cold sample produces a greater entropy change than adding heat to a hot sample.  We can conclude all of this based just upon observing that heat spontaneously flows from a hot piece of metal to a cold piece of metal.  What is harder to conclude is what the exact inverse relationship is.  With much more effort and mathematical reasoning, we can show that the correct inverse relationship between entropy change and temperature is the simplest inverse relationship, namely an inverse proportion:</para>
      <para id="import-auto-id5543743">∆S = q/T <space/><space/> <emphasis effect="italics">for transfer of heat q at temperature T</emphasis></para><para id="import-auto-id6997144">This equation works when the temperature is held constant during the heating process.  If the temperature is not held constant, we have to do an integral of 1/T from the initial temperature to the final temperature to calculate ∆S.  That is not important for our purposes here.  But it is interesting to ask how we can heat a body without changing its temperature.  We will discuss this in the next section.</para></section><section id="fs-id1165692568630"><title>Observation 5: Heat Transfer during Chemical or Physical Processes</title>
      <para id="import-auto-id8888072">The results of the previous observations and reasoning are important in all cases where heat is transferred, not just in heat transfers involving substances at two different temperatures.  Let’s think back to our goal here.  How can the Second Law be applied to a process in a system that is not isolated? We would like to understand how it is possible for a process in a non-isolated system to be spontaneous when ∆S &lt; 0 for the system in that process.  A good example is the freezing of water at temperatures below 0 ºC. What is so special about 0 ºC?  Why is it that below this temperature, the freezing process becomes spontaneous even though ∆S &lt; 0?</para><para id="import-auto-id6692455">Let’s observe the entropy changes for freezing water at -10 ºC, which we know to be a spontaneous process.  First, let’s calculate the ∆S for the process H<sub>2</sub>O(<emphasis effect="italics">l</emphasis>) → H<sub>2</sub>O(<emphasis effect="italics">s</emphasis>) near 0 ºC.  We can do this from a table of absolute entropies, such as in the previous Concept Development Study. At 0 ºC, S for H<sub>2</sub>O(<emphasis effect="italics">l</emphasis>)  = 63.3 J/mol·K and S for H<sub>2</sub>O(<emphasis effect="italics">s</emphasis>) = 41.3 J/mol·K, so for the freezing of water, ∆S = -22.0 J/mol·K.  As expected, this is less than zero.</para>
      <para id="import-auto-id4842210">We know from our previous observation that, since freezing releases heat into the surroundings, then freezing must increase the entropy of the surroundings.  Let’s calculate this change in entropy, ∆S<sub>surroundings</sub>. We will assume quite reasonably and fairly generally that the only effect on the entropy of the surroundings of the freezing taking place in the system is the transfer of heat from the system to the surroundings. There is no other exchange or interaction which happens. We might expect that releasing heat into the surroundings would change the temperature of the surroundings.  However, the surroundings are typically huge (e.g. the entire room in which the process occurs) that the effect of the heat transfer into the surroundings does not make a measurable change in the surrounding temperature.  The same is true when energy is absorbed from the surroundings into the system.  </para><para id="import-auto-id4377374">From our Concept Development Study on energy changes, we can calculate the heat transfer for a process occurring under constant pressure from the enthalpy change for the process, <emphasis effect="italics">q </emphasis>= ΔHº.  By conservation of energy, the heat flow out of or into the surroundings must be –ΔHº.  From our previous observation, the entropy change resulting from this transfer of heat is</para>
      <para id="import-auto-id8894609">∆S°<sub>surroundings</sub> = q/T = -∆H°/T</para><para id="import-auto-id5397638">In this equation, ∆H is the enthalpy change for the system, which is why there is a negative sign in this equation. Notice that, if the process releases energy as is the case in freezing, ∆H° &lt; 0 so ∆S°<sub>surroundings</sub> &gt; 0.  </para><para id="import-auto-id3624636">For H<sub>2</sub>O(<emphasis effect="italics">l</emphasis>) → H<sub>2</sub>O(<emphasis effect="italics">s</emphasis>), ∆Hº = ∆Hº<sub>f</sub>(H<sub>2</sub>O(s)) - ∆Hº<sub>f</sub>(H<sub>2</sub>O(<emphasis effect="italics">l</emphasis>)).  From the data tables, we can calculate that ∆Hº = -6.02 kJ/mol.  As expected, this is less than zero.  From this, we can calculate that at -10 ºC = 263 K, ∆S°<sub>surroundings</sub> = 22.9 J/mol·K.  Again, as expected, this is greater than zero.</para><para id="import-auto-id7336948">We now come to the most important observation: the entropy increase of the surroundings is greater than the entropy decrease of the water that is freezing.  This means that, in total, the entropy change for both system and surroundings is positive.</para>
      <para id="import-auto-id5092798">The conclusion of this observation is that, in analyzing whether a process is spontaneous or not, we must consider both the change in entropy of the system undergoing the process <emphasis effect="underline">and</emphasis> the effect of the heat released or absorbed during the process on the entropy of the surroundings.  In other words, we have to consider the entropy change of the universe:</para>
      <para id="import-auto-id7715602">∆S<sub>universe</sub> = ∆S<sub>system</sub> + ∆S<sub>surroundings</sub></para><para id="import-auto-id8309126">We can say then that </para>
      <para id="import-auto-id8572236">∆S<sub>universe</sub> = ∆S<sub>system</sub> + ∆S<sub>surroundings</sub> = ∆S<sub>system</sub> - ∆H<sub>system</sub>/T</para><para id="import-auto-id8829483">The last part of this equation says that we can calculate the entropy change of the universe from calculations that involve only entropy and energy changes in the system.  This sounds very doable!  For every spontaneous process, ∆S<sub>universe</sub> &gt; 0, so for every spontaneous process:</para><para id="import-auto-id4755112">∆S<sub>system</sub> - ∆H<sub>system</sub>/T &gt; 0</para><para id="import-auto-id5020994">In this inequality, the entropy change and the enthalpy change are both for the system, so the subscripts are now not needed and we can drop them to make the equation easier to read.</para>
      <para id="import-auto-id8462549"><emphasis effect="italics">∆S - ∆H/T &gt; 0 <space/><space/>any spontaneous process</emphasis>
      </para><para id="import-auto-id8313666">The fact that the temperature appears in this equation is very interesting.  Remember why it is there in the denominator: the effect on the entropy of the heat exchange with the surroundings is smaller when the temperature is larger.  </para>
      <para id="import-auto-id4895060">This also suggests that we try our calculation with a different temperature.  What if the temperature is 10 ºC, above the freezing point?  In this case, we observe experimentally that the melting of solid ice is spontaneous.  Let’s do the calculation of the inequality above for the process H<sub>2</sub>O(<emphasis effect="italics">l</emphasis>) → H<sub>2</sub>O(<emphasis effect="italics">s</emphasis>) at 10 ºC.  As before, ∆Hº = -6.02 kJ/mol and ∆Sº = -22.0 J/mol·K, but now T = 283K.  We get that</para>
      <para id="import-auto-id7045324">∆S° - ∆H°/T = -0.73 J/mol·K &lt; 0</para><para id="import-auto-id8668904">We find a negative number, telling us that freezing water is not spontaneous at 10 ºC.  More importantly, we know that the reverse process of melting ice is spontaneous at 10 ºC.  This means that, if ∆S - ∆H/T &lt; 0, the reverse process is spontaneous. </para><para id="import-auto-id8433587">Now we know what is so special about the temperature 0 ºC.  Below that temperature, ∆S° - ∆H°/T &gt; 0 for the freezing of water, and above that temperature ∆S° - ∆H°/T &lt; 0  for the freezing of water, so ∆S° - ∆H°/T &gt; 0 for the melting of ice.  </para><para id="import-auto-id5435121">What happens at 0 ºC?  It is easy to calculate that ∆S° - ∆H°/T = 0 at that temperature.  Of course, at that temperature at standard pressure, water and ice are in equilibrium.  This is a very important observation: when ∆S - ∆H/T = 0, the process is at equilibrium.  We will develop this observation in much greater detail in the next Concept Development Study.</para></section><section id="fs-id1170998611880"><title>Review and Discussion Questions</title>
      <list id="import-auto-id6318116" list-type="enumerated" number-style="arabic"><item>Each possible sequence of the 52 cards in a deck is equally probable.  However, when you shuffle a deck and then examine the sequence, the deck is never ordered.  Explain why in terms of microstates, macrostates, and entropy.</item>
      <item>Assess the validity of the statement, "In all spontaneous processes, the system moves toward a state of lowest energy."  Correct any errors you identify.</item>
      <item>Recalling the discussion of the freezing point of water, determine what must be true about ΔHº and ΔSº for a solid to have a freezing point much higher than that of water.  Similarly, determine what must be true about ΔHº and ΔSº for a solid to have a freezing point much lower than that of water. </item>
<item>Predict the sign of the entropy for the reaction 2 H<sub>2</sub> (g)  +  O<sub>2</sub> (g)  →  2 H<sub>2</sub>O (g). Give an explanation, based on entropy and the Second Law, of why this reaction occurs spontaneously.</item>
      <item>For the reaction H2(g) →  2 H(g), predict the sign of both  ΔHº and ΔSº.  Based on your knowledge of hydrogen, which of these two terms is probably dominant in determining whether the reaction is spontaneous.  What would you predict would be the effect of lowering the temperature?  Explain.</item>
      </list></section>
  </content>
</document>